# ğŸš¨ DroneAid â€” Disaster Relief through Drone-Assisted Victim Identification

<div align="center">

![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![YOLO](https://img.shields.io/badge/Object--Detection-YOLOv8-red)
![License](https://img.shields.io/badge/License-MIT-yellow)

**A resilient, multi-drone AI system to locate survivors in disaster zones using computer vision, thermal sensing, multisensor fusion, and distributed coordination.**

[Features](#-key-features) â€¢ [Quick Start](#-quick-start) â€¢ [Architecture](#-project-architecture) â€¢ [API](#-api-reference)

</div>

---

## ğŸŒŸ Key Features

### ğŸ§  YOLOv8 Object Detection  
Like a vigilant eye watching over the disaster zone, YOLOv8 scans every frame in real time. The moment it detects a human or animal, it highlights them instantly â€” ensuring no potential victim goes unnoticed.  

---

### ğŸ¥ OpenCV Live Video Streaming  
OpenCV acts as the heartbeat of the system. It keeps the camera feed flowing smoothly, turning raw visuals into searchable signals, frame after frame, without missing a moment. 

---

### ğŸŒ Flask-Powered Web Dashboard  
Flask becomes the command center that brings everything together. A lightweight live dashboard displays the feed, detection boxes, and captured alerts â€” making monitoring effortless on any device.  

---

### âš™ï¸ Multi-Threaded Processing Engine  
Multiple threads work like a coordinated rescue unit behind the scenes. One captures video, another runs detection, another saves outputs â€” all in perfect sync, ensuring real-time responsiveness during emergencies.  

---

### ğŸ“ JSON-Based Detection Logging  
Every confirmed detection is stored neatly in `detections.json`. Timestamp, confidence, file paths â€” all recorded, creating a reliable digital trail that supports faster rescue decisions.


## âš™ï¸ Tech Stack

#### ğŸ Python --> ![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)

#### ğŸŒ Flask --> ![Flask](https://img.shields.io/badge/Flask-000000?style=for-the-badge&logo=flask&logoColor=white)

#### ğŸ¤– YOLOv8 (Ultralytics) --> ![YOLO](https://img.shields.io/badge/YOLOv8-FF6F00?style=for-the-badge&logo=ai&logoColor=white)

#### ğŸ¥ OpenCV --> ![OpenCV](https://img.shields.io/badge/OpenCV-5C3EE8?style=for-the-badge&logo=opencv&logoColor=white)

#### ğŸ§µ Threading --> ![Threading](https://img.shields.io/badge/Threading-FFD43B?style=for-the-badge&logo=python&logoColor=black)

#### ğŸ”— Requests Library -->![Requests](https://img.shields.io/badge/Requests-000000?style=for-the-badge&logo=python&logoColor=white)

#### ğŸ–¼ HTML + Jinja Templates --> ![HTML](https://img.shields.io/badge/HTML-Jinja2-orange?style=for-the-badge)


## ğŸ—ï¸ Project Architecture

```
drone-rescue-ai/
â”‚
â”œâ”€â”€ ğŸ“ static/                          # Public assets served by Flask
â”‚   â”œâ”€â”€ ğŸ“ detections/                  # Saved YOLO-annotated output images
â”‚   â””â”€â”€ ğŸ“ images/                      # Raw uploaded/test images
â”‚
â”œâ”€â”€ ğŸ“ templates/                       # Flask HTML UI (Jinja2 templates)
â”‚   â””â”€â”€ index.html                      # Live video feed + detection dashboard
â”‚
â”œâ”€â”€ app.py                              # Main Flask backend (video stream + YOLO inference)
â”œâ”€â”€ detections.json                     # Auto-generated detection logs (JSON format)
â”œâ”€â”€ yolov8n.pt                          # YOLOv8 model weights (Ultralytics)
â”œâ”€â”€ test.jpg                            # Sample image for testing detection
â”œâ”€â”€ .env                                # Environment variables (API keys, configs)
â”œâ”€â”€ .gitignore                          # Git ignored files
â””â”€â”€ README.md                           # Project documentation
```

